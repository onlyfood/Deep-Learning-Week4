{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Git:https://github.com/onlyfood/Deep-Learning-Week4.git","metadata":{}},{"cell_type":"markdown","source":"# Problem/Data Description:\n# The data provided for this analysis is from a Kaggle competition titled \"Natural Language Processing with Disaster Tweets.\" The objective of the competition is to classify disaster-related tweets as either referring to a real disaster (1) or not (0). The dataset consists of a training set and a test set, both containing tweet text and their corresponding labels.\n# \n# The problem is of great importance as accurate classification of disaster tweets can help in timely response and effective allocation of resources during emergencies. It can also aid in monitoring and understanding public sentiment during crisis situations.\n# \n# Discussion/Conclusion:\n# In this analysis, we explored a dataset that contains disaster-related tweets and their labels. We performed exploratory data analysis (EDA) to gain insights into the data and understand its characteristics.\n# \n# During the EDA, we examined the shape of the training and test datasets and observed the first few rows to get a sense of the data structure. We also analyzed the distribution of the target variable, which indicated the proportion of disaster-related tweets in the dataset.\n# \n# Moving forward, we preprocessed the text data by applying necessary cleaning and transformation techniques. We used a CountVectorizer to convert the text data into numerical representations that can be used for modeling.\n# \n# A logistic regression model was trained on the preprocessed data to classify disaster-related tweets. The model achieved a validation accuracy of X%, indicating its ability to accurately predict whether a tweet refers to a real disaster or not.\n# \n# In conclusion, this analysis demonstrates the potential of natural language processing techniques to classify disaster tweets. The trained model can be applied to classify new, unseen tweets and aid in real-time emergency response and sentiment analysis during crisis situations.\n# \n# Further improvements can be made by exploring advanced natural language processing models, feature engineering, and hyperparameter tuning. Additionally, the model's performance can be evaluated using additional evaluation metrics and compared with other models to identify the most effective approach for classifying disaster tweets.\n# \n# By addressing this problem effectively, we can contribute to enhancing emergency response systems and providing valuable insights for disaster management and public safety.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-06T01:00:50.191853Z","iopub.execute_input":"2023-06-06T01:00:50.192248Z","iopub.status.idle":"2023-06-06T01:00:50.232236Z","shell.execute_reply.started":"2023-06-06T01:00:50.192215Z","shell.execute_reply":"2023-06-06T01:00:50.231204Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport re\nimport string","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:01:02.240898Z","iopub.execute_input":"2023-06-06T01:01:02.241249Z","iopub.status.idle":"2023-06-06T01:01:02.998804Z","shell.execute_reply.started":"2023-06-06T01:01:02.241226Z","shell.execute_reply":"2023-06-06T01:01:02.997799Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\ntrain_data = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntest_data = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:01:26.956693Z","iopub.execute_input":"2023-06-06T01:01:26.957080Z","iopub.status.idle":"2023-06-06T01:01:27.029633Z","shell.execute_reply.started":"2023-06-06T01:01:26.957041Z","shell.execute_reply":"2023-06-06T01:01:27.028823Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Preprocessing function\ndef preprocess_text(text):\n    # Remove URLs\n    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n    \n    # Remove punctuation\n    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n    \n    # Convert to lowercase\n    text = text.lower()\n    \n    return text\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:01:36.897934Z","iopub.execute_input":"2023-06-06T01:01:36.898422Z","iopub.status.idle":"2023-06-06T01:01:36.907409Z","shell.execute_reply.started":"2023-06-06T01:01:36.898385Z","shell.execute_reply":"2023-06-06T01:01:36.904539Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Apply preprocessing to the text data\ntrain_data['preprocessed_text'] = train_data['text'].apply(preprocess_text)\ntest_data['preprocessed_text'] = test_data['text'].apply(preprocess_text)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:01:45.050484Z","iopub.execute_input":"2023-06-06T01:01:45.051111Z","iopub.status.idle":"2023-06-06T01:01:45.153436Z","shell.execute_reply.started":"2023-06-06T01:01:45.051053Z","shell.execute_reply":"2023-06-06T01:01:45.152376Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(train_data['preprocessed_text'], train_data['target'], test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:01:54.252268Z","iopub.execute_input":"2023-06-06T01:01:54.252618Z","iopub.status.idle":"2023-06-06T01:01:54.264357Z","shell.execute_reply.started":"2023-06-06T01:01:54.252588Z","shell.execute_reply":"2023-06-06T01:01:54.263020Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Vectorize the text data using a Bag-of-Words approach\nvectorizer = CountVectorizer()\nX_train_vectorized = vectorizer.fit_transform(X_train)\nX_val_vectorized = vectorizer.transform(X_val)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:02:03.545149Z","iopub.execute_input":"2023-06-06T01:02:03.545702Z","iopub.status.idle":"2023-06-06T01:02:03.699777Z","shell.execute_reply.started":"2023-06-06T01:02:03.545659Z","shell.execute_reply":"2023-06-06T01:02:03.698115Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Train a logistic regression model\nmodel = LogisticRegression()\nmodel.fit(X_train_vectorized, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:02:14.300984Z","iopub.execute_input":"2023-06-06T01:02:14.301376Z","iopub.status.idle":"2023-06-06T01:02:14.688304Z","shell.execute_reply.started":"2023-06-06T01:02:14.301346Z","shell.execute_reply":"2023-06-06T01:02:14.687489Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"LogisticRegression()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# Make predictions on the validation set\nval_predictions = model.predict(X_val_vectorized)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:02:21.331413Z","iopub.execute_input":"2023-06-06T01:02:21.332745Z","iopub.status.idle":"2023-06-06T01:02:21.339002Z","shell.execute_reply.started":"2023-06-06T01:02:21.332686Z","shell.execute_reply":"2023-06-06T01:02:21.337207Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Calculate accuracy on the validation set\naccuracy = accuracy_score(y_val, val_predictions)\nprint(\"Validation Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:02:32.530930Z","iopub.execute_input":"2023-06-06T01:02:32.531271Z","iopub.status.idle":"2023-06-06T01:02:32.538028Z","shell.execute_reply.started":"2023-06-06T01:02:32.531243Z","shell.execute_reply":"2023-06-06T01:02:32.537143Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.8023637557452397\n","output_type":"stream"}]},{"cell_type":"code","source":"# Vectorize the test data\nX_test_vectorized = vectorizer.transform(test_data['preprocessed_text'])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:02:45.652918Z","iopub.execute_input":"2023-06-06T01:02:45.653289Z","iopub.status.idle":"2023-06-06T01:02:45.706682Z","shell.execute_reply.started":"2023-06-06T01:02:45.653263Z","shell.execute_reply":"2023-06-06T01:02:45.704295Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test set\ntest_predictions = model.predict(X_test_vectorized)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:02:46.795722Z","iopub.execute_input":"2023-06-06T01:02:46.796097Z","iopub.status.idle":"2023-06-06T01:02:46.805521Z","shell.execute_reply.started":"2023-06-06T01:02:46.796047Z","shell.execute_reply":"2023-06-06T01:02:46.804689Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Prepare submission file\nsubmission = pd.DataFrame({'id': test_data['id'], 'target': test_predictions})\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:02:54.606213Z","iopub.execute_input":"2023-06-06T01:02:54.606562Z","iopub.status.idle":"2023-06-06T01:02:54.610654Z","shell.execute_reply.started":"2023-06-06T01:02:54.606541Z","shell.execute_reply":"2023-06-06T01:02:54.610015Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Save submission file\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T01:03:07.943215Z","iopub.execute_input":"2023-06-06T01:03:07.943631Z","iopub.status.idle":"2023-06-06T01:03:07.953756Z","shell.execute_reply.started":"2023-06-06T01:03:07.943599Z","shell.execute_reply":"2023-06-06T01:03:07.952955Z"},"trusted":true},"execution_count":15,"outputs":[]}]}